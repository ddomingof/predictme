{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from rpy2.rinterface import RRuntimeWarning\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=RRuntimeWarning)\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable R magic\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danieldomingo/PycharmProjects/predictme/data\n"
     ]
    }
   ],
   "source": [
    "HERE = os.path.dirname(os.path.realpath('__file__'))\n",
    "PROJECT = os.path.abspath(os.path.join(HERE, '..'))\n",
    "DATA = os.path.join(PROJECT, 'data')\n",
    "\n",
    "print(DATA)\n",
    "\n",
    "ADPD_SNPS_DATA = os.path.join(DATA, 'adpd_snp_mat.RData')\n",
    "ADPD_AUTOENCODER_MODELS = os.path.join(DATA, \"models\")\n",
    "ADPD_AUTOENCODER_MODEL_STORE = os.path.join(DATA, 'adpd_autoencoder_model_store.RData')\n",
    "AUTOENCODER_TRAINED_MATRIX = os.path.join(DATA, \"autoencoder_trained_matrix.RData\")\n",
    "TRAINED_PATIENT_CLUSTERS = os.path.join(DATA, \"trained_patient_clusters.RData\")\n",
    "\n",
    "USER_DATA = os.path.join(DATA, 'Asif_Genotype_Disease_Only_ROSMAP.csv')\n",
    "SUGBRAPH_SNPS = os.path.join(DATA, 'subgraphs15_snps_mod1.csv')\n",
    "SUBGRAPH_15_RDATA = os.path.join(DATA, 'subgraph15_snpset148.RData')\n",
    "\n",
    "INPUT_FOR_MODEL = os.path.join(DATA, \"rosmap148.snp.mat.RData\")\n",
    "CLUSTER_CLASSIFIER = os.path.join(DATA, \"GLM_model_R\")\n",
    "\n",
    "PREDICTED_USERDATA = os.path.join(DATA, \"predicted_userdata.RData\")\n",
    "PREDICTED_USER_Clusters = os.path.join(DATA, \"predicted_user_clusters.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Your next step is to start H2O:\n",
      "    > h2o.init()\n",
      "\n",
      "For H2O package documentation, ask for help:\n",
      "    > ??h2o\n",
      "\n",
      "After starting H2O, you can use the Web UI at http://localhost:54321\n",
      "For more information visit http://docs.h2o.ai\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attache Paket: ‘h2o’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    cor, sd, var\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    %*%, %in%, &&, apply, as.factor, as.numeric, colnames, colnames<-,\n",
      "    ifelse, is.character, is.factor, is.numeric, log, log10, log1p,\n",
      "    log2, round, signif, trunc, ||\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attache Paket: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "R[write to console]: Lade nötiges Paket: foreach\n",
      "\n",
      "R[write to console]: Lade nötiges Paket: iterators\n",
      "\n",
      "R[write to console]: Lade nötiges Paket: parallel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(h2o)\n",
    "library(dplyr)\n",
    "library(doParallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#### main function ####\n",
    "\n",
    "ann_fun = function(input_data){\n",
    "  if(dim(input_data)[2] > 1)\n",
    "  {\n",
    "    h2o.init(nthreads = -1, max_mem_size = \"12g\")\n",
    "    \n",
    "    #sc = scale(input_data)\n",
    "    myx = as.h2o(scale(input_data)) \n",
    "    \n",
    "    n = round(dim(input_data)[2])\n",
    "    m = round(dim(input_data)[2]/2)\n",
    "    \n",
    "    hyper_params <- list(hidden = list(1, c(n, 1), c(n,m,1), c(m,1)),\n",
    "                         input_dropout_ratio = c(0,0.05, 0.2,0.5),\n",
    "                         l2=10^c(-4:4))\n",
    "    \n",
    "    \n",
    "    r = sample(20:60000, 1)\n",
    " \n",
    "  grid = h2o.grid(\"deeplearning\", \n",
    "                    grid_id = paste(\"mygrid\", r, sep=\"_\"), \n",
    "                    autoencoder= TRUE,\n",
    "                  x = colnames(myx),\n",
    "                    training_frame = myx, \n",
    "                    seed=1234567, \n",
    "                    stopping_metric=\"MSE\", \n",
    "                    stopping_rounds = 5,\n",
    "                    #activation= \"TanhWithDropout\",\n",
    "                    activation= \"Tanh\",\n",
    "                    standardize=TRUE,\n",
    "                    epochs=500,\n",
    "                    hyper_params = hyper_params)\n",
    "    \n",
    "    gbm_sorted_grid <- h2o.getGrid(grid_id = paste(\"mygrid\", r, sep=\"_\"), sort_by = \"mse\")\n",
    "    fit <- h2o.getModel(gbm_sorted_grid@model_ids[[1]])\n",
    "    #nlayers = length(strsplit(gbm_sorted_grid@summary_table[1,1], \",\")[[1]])\n",
    "    #browser()\n",
    "    nlayers = length(strsplit(substr(gbm_sorted_grid@summary_table[1,1], 2, nchar(gbm_sorted_grid@summary_table[1,1])-1), \",\")[[1]])\n",
    "    newvar = as.data.frame(h2o.deepfeatures(fit, myx, nlayers))\n",
    " \n",
    "  \n",
    "    #Rename column\n",
    " \n",
    "    newvar = as.data.frame(newvar[,1])\n",
    "    colnames(newvar) = paste( sub(\"_.*\", '', colnames(input_data)[1]) , sub(\".*_\", '',colnames(input_data)[1]) , sep= \"_\")\n",
    "    \n",
    "   \n",
    "    #save meta-features in variable \n",
    "    subgraph_feature = data.frame(matrix(NA, nrow = 844, ncol = 1)) # nrow = Patient number\n",
    "    colnames(subgraph_feature) = \"dummy\"\n",
    " \n",
    "  \n",
    "    subgraph_feature = cbind(subgraph_feature,newvar) \n",
    "    subgraph_feature$dummy = NULL\n",
    "    \n",
    "  }else if(dim(input_data)[2] == 1 ){\n",
    "    subgraph_feature = as.data.frame(input_data)\n",
    "    colnames(newvar) = paste( sub(\"_.*\", '', colnames(input_data)[1]) , sub(\".*_\", '',colnames(input_data)[1]) , sep= \"_\")\n",
    "  }else{\n",
    "    subgraph_feature = data.frame(matrix(NA, nrow = 844, ncol = 1)) # nrow = Patient number\n",
    "    colnames(subgraph_feature) = \"dummy\"\n",
    "  }\n",
    "  outcome = list(subgraph_feature, fit) # scales=attributes(sc)\n",
    "  return(outcome)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H2O is not running yet, starting it now...\n",
      "\n",
      "Note:  In case of errors look at the following log files:\n",
      "    /var/folders/yx/ppwbtpyn61l2796mnr1t62f00000gn/T//Rtmp6rhN2K/h2o_danieldomingo_started_from_r.out\n",
      "    /var/folders/yx/ppwbtpyn61l2796mnr1t62f00000gn/T//Rtmp6rhN2K/h2o_danieldomingo_started_from_r.err\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: ... Connection successful!\n",
      "\n",
      "R is connected to the H2O cluster: \n",
      "    H2O cluster uptime:         5 seconds 432 milliseconds \n",
      "    H2O cluster timezone:       Europe/Berlin \n",
      "    H2O data parsing timezone:  UTC \n",
      "    H2O cluster version:        3.28.0.2 \n",
      "    H2O cluster version age:    6 days  \n",
      "    H2O cluster name:           H2O_started_from_R_danieldomingo_iwe304 \n",
      "    H2O cluster total nodes:    1 \n",
      "    H2O cluster total memory:   10.66 GB \n",
      "    H2O cluster total cores:    4 \n",
      "    H2O cluster allowed cores:  4 \n",
      "    H2O cluster healthy:        TRUE \n",
      "    H2O Connection ip:          localhost \n",
      "    H2O Connection port:        54321 \n",
      "    H2O Connection proxy:       NA \n",
      "    H2O Internal Security:      FALSE \n",
      "    H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4 \n",
      "    R Version:                  R version 3.6.2 (2019-12-12) \n",
      "\n",
      "  |======================================================================| 100%\n",
      "  |=====                                                                 |   7%"
     ]
    }
   ],
   "source": [
    "%%R -i=ADPD_SNPS_DATA,ADPD_AUTOENCODER_MODEL,ADPD_SNPS_DATA\n",
    "# see: https://ipython.org/ipython-doc/2/config/extensions/rmagic.html\n",
    "\n",
    "load(ADPD_SNPS_DATA)\n",
    "# apply main function on each mechanisms matrices\n",
    "model.store <- lapply(snp_mat, function(x) ann_fun(x))\n",
    "                      \n",
    "# Stores the model\n",
    "# save(model.store, file = \"model.store.rosmapIdibaps-148_full.RData\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model.store, file = \"new-model.store.rosmapIdibaps-148_full.RData\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "adpd_autoencoder_matrix=matrix(nrow = 844, ncol = 15) # 358 PD patients and 15 subgraphs\n",
    "\n",
    "j=1\n",
    "for (i in model.store){\n",
    "  autoen[,j]=i[[1]][[1]]\n",
    "  j=j+1\n",
    "}\n",
    "rownames(autoen) <- rownames(snp_mat[[1]])\n",
    "colnames(autoen) <- names(model.store)\n",
    "save(adpd_autoencoder_matrix, file = ADPD_AUTOENCODER_MATRIX)\n",
    "\n",
    "#~~~~~: save models in h2o format :~~~~~~#\n",
    "\n",
    "an_model <- lapply(model.store, '[[',2)  # This returns a list with only the 2nd element (h2o models)\n",
    "\n",
    "for (i in an_model){\n",
    "  h2o.saveModel(i, path = ADPD_AUTOENCODER_MODEL)\n",
    "}                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i=SUBGRAPH_15_RDATA,USER_DATA,INPUT_FOR_MODEL\n",
    "\n",
    "load(SUBGRAPH_15_RDATA)\n",
    "userSNPs <- read.csv(USER_DATA, row.names = 1, stringsAsFactors=FALSE)\n",
    "userSNPs <- as.data.frame(t(userSNPs), stringsAsFactors = FALSE)\n",
    "\n",
    "user_snp_mat = list()\n",
    "k = 1\n",
    "for (i in subgraph15.snps){\n",
    "  user_snp_mat[[k]] = select(userSNPs, i)\n",
    "  k = k + 1\n",
    "}\n",
    "\n",
    "names(user_snp_mat) <- names(subgraph15.snps)\n",
    "save(user_snp_mat,file = INPUT_FOR_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict User data matrix based on our Training Dataset autoencoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connection successful!\n",
      "\n",
      "R is connected to the H2O cluster: \n",
      "    H2O cluster uptime:         58 minutes 3 seconds \n",
      "    H2O cluster timezone:       Europe/Berlin \n",
      "    H2O data parsing timezone:  UTC \n",
      "    H2O cluster version:        3.26.0.2 \n",
      "    H2O cluster version age:    6 months !!! \n",
      "    H2O cluster name:           H2O_started_from_R_danieldomingo_duc237 \n",
      "    H2O cluster total nodes:    1 \n",
      "    H2O cluster total memory:   5.68 GB \n",
      "    H2O cluster total cores:    4 \n",
      "    H2O cluster allowed cores:  4 \n",
      "    H2O cluster healthy:        TRUE \n",
      "    H2O Connection ip:          localhost \n",
      "    H2O Connection port:        54321 \n",
      "    H2O Connection proxy:       NA \n",
      "    H2O Internal Security:      FALSE \n",
      "    H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4 \n",
      "    R Version:                  R version 3.6.2 (2019-12-12) \n",
      "\n",
      "  |======================================================================| 100%\n",
      "[[1]]\n",
      "NULL\n",
      "\n",
      "[[2]]\n",
      "NULL\n",
      "\n",
      "[[3]]\n",
      "NULL\n",
      "\n",
      "[[4]]\n",
      "NULL\n",
      "\n",
      "[[5]]\n",
      "NULL\n",
      "\n",
      "[[6]]\n",
      "NULL\n",
      "\n",
      "[[7]]\n",
      "NULL\n",
      "\n",
      "[[8]]\n",
      "NULL\n",
      "\n",
      "[[9]]\n",
      "NULL\n",
      "\n",
      "[[10]]\n",
      "NULL\n",
      "\n",
      "[[11]]\n",
      "NULL\n",
      "\n",
      "[[12]]\n",
      "NULL\n",
      "\n",
      "[[13]]\n",
      "NULL\n",
      "\n",
      "[[14]]\n",
      "NULL\n",
      "\n",
      "[[15]]\n",
      "NULL\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Fehler in names(predicted_userdata) <- names(model.store) : \n",
      "  se intenta especificar un atributo en un NULL\n",
      "Ruft auf: <Anonymous> -> <Anonymous> -> withVisible\n",
      "\n",
      "R[write to console]: Además: \n",
      "R[write to console]: Warnmeldung:\n",
      "\n",
      "R[write to console]: In h2o.clusterInfo() :\n",
      "R[write to console]:  \n",
      "Your H2O cluster version is too old (6 months)!\n",
      "Please download and install the latest version from http://h2o.ai/download/\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fehler in names(predicted_userdata) <- names(model.store) : \n",
      "  se intenta especificar un atributo en un NULL\n",
      "Ruft auf: <Anonymous> -> <Anonymous> -> withVisible\n"
     ]
    }
   ],
   "source": [
    "%%R -i=ADPD_AUTOENCODER_MODEL_STORE,ADPD_AUTOENCODER_MODELS,INPUT_FOR_MODEL,PREDICTED_USERDATA\n",
    "#~~~~~: Predict User data matrix based on our Training dataset autoencoder models :~~~~#\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "#~~~~~~~~~~: load trained autoencoder matrix :~~~~~~~~~~#\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "load(ADPD_AUTOENCODER_MODEL_STORE)\n",
    "\n",
    "#~~~~~~~~~~: load trained autoencoder models :~~~~~~~~~~#\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "h2o.init()\n",
    "setwd(ADPD_AUTOENCODER_MODELS)\n",
    "modelnames <-list.files(path = \".\")\n",
    "models = lapply(paste0(getwd(),\"/\", modelnames), h2o.loadModel)\n",
    "\n",
    "#~~~~~~~~~~: load User files :~~~~~~~~~~#\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "#### all subgraphs (samples * SNPs coding matrix each) into an RData file\n",
    "testmat <- INPUT_FOR_MODEL\n",
    "testh2o <- sapply(1:length(testmat), function(x) as.h2o(testmat[[x]]))\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~: Mechanism Score Prediction :~~~~~~~~~~~~~#\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "predicted_userdata <- foreach(i = seq(model.store)) %do% {\n",
    "  if (length(attributes(models[[model.store[[i]][[2]]@model_id]])$parameters$hidden) == 1) {\n",
    "    tmp = as.data.frame(h2o.deepfeatures(models[[model.store[[i]][[2]]@model_id]], testh2o[[i]], 1))\n",
    "  } else if (length(attributes(models[[model.store[[i]][[2]]@model_id]])$parameters$hidden) > 1){\n",
    "    tmp = as.data.frame(h2o.deepfeatures(models[[model.store[[i]][[2]]@model_id]], testh2o[[i]], 2))\n",
    "    tmp = cbind(tmp)\n",
    "  }\n",
    "}\n",
    "\n",
    "print(predicted_userdata)\n",
    "predicted_userdata <- do.call(cbind, pred)\n",
    "names(predicted_userdata) <- names(model.store)\n",
    "rownames(predicted_userdata) <- rownames(userSNPs)\n",
    "save(predicted_userdata,file = PREDICTED_USERDATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Clusters for User Data based on the Classifier trained with Training Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H2O is not running yet, starting it now...\n",
      "\n",
      "Note:  In case of errors look at the following log files:\n",
      "    /var/folders/yx/ppwbtpyn61l2796mnr1t62f00000gn/T//RtmpwXjRnz/h2o_danieldomingo_started_from_r.out\n",
      "    /var/folders/yx/ppwbtpyn61l2796mnr1t62f00000gn/T//RtmpwXjRnz/h2o_danieldomingo_started_from_r.err\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: . Connection successful!\n",
      "\n",
      "R is connected to the H2O cluster: \n",
      "    H2O cluster uptime:         2 seconds 242 milliseconds \n",
      "    H2O cluster timezone:       Europe/Berlin \n",
      "    H2O data parsing timezone:  UTC \n",
      "    H2O cluster version:        3.26.0.2 \n",
      "    H2O cluster version age:    6 months !!! \n",
      "    H2O cluster name:           H2O_started_from_R_danieldomingo_duc237 \n",
      "    H2O cluster total nodes:    1 \n",
      "    H2O cluster total memory:   5.75 GB \n",
      "    H2O cluster total cores:    4 \n",
      "    H2O cluster allowed cores:  4 \n",
      "    H2O cluster healthy:        TRUE \n",
      "    H2O Connection ip:          localhost \n",
      "    H2O Connection port:        54321 \n",
      "    H2O Connection proxy:       NA \n",
      "    H2O Internal Security:      FALSE \n",
      "    H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4 \n",
      "    R Version:                  R version 3.6.2 (2019-12-12) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Fehler in readChar(con, 5L, useBytes = TRUE) : \n",
      "  no se puede abrir la conexión\n",
      "Ruft auf: <Anonymous> -> <Anonymous> -> withVisible -> load -> readChar\n",
      "\n",
      "R[write to console]: Además: \n",
      "R[write to console]: Warnmeldungen:\n",
      "\n",
      "R[write to console]: 1: \n",
      "R[write to console]: In h2o.clusterInfo() :\n",
      "R[write to console]:  \n",
      "Your H2O cluster version is too old (6 months)!\n",
      "Please download and install the latest version from http://h2o.ai/download/\n",
      "\n",
      "R[write to console]: 2: \n",
      "R[write to console]: In readChar(con, 5L, useBytes = TRUE) :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  cannot open file '/Users/danieldomingo/PycharmProjects/predictme/data/models': it is a directory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fehler in readChar(con, 5L, useBytes = TRUE) : \n",
      "  no se puede abrir la conexión\n",
      "Ruft auf: <Anonymous> -> <Anonymous> -> withVisible -> load -> readChar\n"
     ]
    }
   ],
   "source": [
    "%%R -i=AUTOENCODER_TRAINED_MATRIX,TRAINED_PATIENT_CLUSTERS,CLUSTER_CLASSIFIER\n",
    "\n",
    "### Start up a 1-node H2O server on the local machine, and allow it to use all CPU cores and up to 6GB of memory:\n",
    "h2o.init(nthreads=-1, min_mem_size=\"6G\")\n",
    "\n",
    "### Import autoencoder data set #subgraph15\n",
    "load(AUTOENCODER_TRAINED_MATRIX)\n",
    "main_data <- data.frame(autoen)\n",
    "\n",
    "#### read the cluster assignments of each patients\n",
    "load(TRAINED_PATIENT_CLUSTERS)\n",
    "rownames(clusters) <- clusters[,1]\n",
    "clusters[,1] <- NULL\n",
    "\n",
    "\n",
    "##### merge cluster assignment to the dataset\n",
    "fin_data <- merge(clusters,main_data,by=\"row.names\")\n",
    "fin_data$clusters <- as.factor(fin_data$clusters)\n",
    "rownames(fin_data) = fin_data$Row.names\n",
    "fin_data <- fin_data[,-1]\n",
    "fullD <- as.h2o(fin_data) # get complete data set into h2o frame for cross validation approach\n",
    "\n",
    "##### Training Classifier\n",
    "\n",
    "y = \"clusters\" # response variable\n",
    "#x = names(trainData)\n",
    "x = names(fullD)\n",
    "x = x[-which(x==y)] # predictor variables\n",
    "\n",
    "### Train Model\n",
    "snpModel = h2o.glm(training_frame = fullD, \n",
    "                   #training_frame = trainD, # keep it commented while using cross validation\n",
    "                   #validation_frame = validD, # keep it commented while using cross validation\n",
    "                   x = x, \n",
    "                   y = y,\n",
    "                   nfolds = 10, \n",
    "                   family='multinomial',\n",
    "                   solver='L_BFGS',\n",
    "                   lambda_search=TRUE)\n",
    "\n",
    "print(snpModel)\n",
    "h2o.performance(snpModel, xval = TRUE)\n",
    "h2o.saveModel(snpModel, path=CLUSTER_CLASSIFIER)\n",
    "\n",
    "#### Now predict the Test Data with the trained model #####\n",
    "#snpModel = h2o.loadModel(\"/home/memon/genetic_analyses/ann/output/subgraph15/classifier_adpd_ann30/GLM_model_R_1552061363922_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i=CLUSTER_CLASSIFIER\n",
    "\n",
    "#### Now predict the Test Data with the trained model #####\n",
    "snpModel = h2o.loadModel(CLUSTER_CLASSIFIER)\n",
    "\n",
    "#### for autoencoder predcited AET_PD data based predcition ####\n",
    "load(PREDICTED_USERDATA) # rosmap dataset predcited (h2o.deepfeature) with autoen30 model\n",
    "testh2o <- as.h2o(predicted_userdata)\n",
    "\n",
    "##########################################\n",
    "\n",
    "### prediction on test data set\n",
    "prediction = h2o.predict(snpModel, newdata=testh2o)\n",
    "\n",
    "predicted.cl = as.data.frame(prediction$predict)\n",
    "names(predicted.cl) <- \"clusters\"\n",
    "predicted.cl$clusters <- as.integer(as.character(gsub(\"Cluster_\", \"\", predicted.cl$clusters)))\n",
    "\n",
    "# merge predicted clusters to test data\n",
    "# so all patients in test data set get a cluster assignment based on their mechanism profile (predictro variables)\n",
    "predicted_cl.testdata <- cbind(predicted.cl,testdata)\n",
    "#save(predicted_cl.testdata,file=\"/home/memon/genetic_analyses/ann/output/subgraph15/ann30_cluster_prediction_adni148_nonad.RData\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "autoen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
